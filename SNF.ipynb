{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import snf\n",
    "from snf import metrics\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data():\n",
    "    # Proteomics\n",
    "    #prot_raw = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/proteomics/proteomics_corr_raw_203.csv')\n",
    "    prot = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/proteomics/normalized_imp_corrected_proteomics204_03292022.csv')\n",
    "    #prot_raw = prot_raw.set_index('Unnamed: 0')\n",
    "    prot = prot.set_index('Unnamed: 0')\n",
    "    \n",
    "    # Transcriptomics\n",
    "    #tran_raw = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/transcriptomics/rna_raw_196_02222023.csv')\n",
    "    tran = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/transcriptomics/rna_norm_196_02222023.csv.gz')\n",
    "    #tran_raw = tran_raw.set_index('Unnamed: 0')\n",
    "    tran = tran.set_index('Unnamed: 0')\n",
    "\n",
    "    # Epigenomics\n",
    "    #epig_raw = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/epigenomics/atac_raw_196_02222023.csv')\n",
    "    epig = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/epigenomics/atac_norm_196_02222023.csv.gz')\n",
    "    #epig_raw = epig_raw.set_index('Unnamed: 0')\n",
    "    epig = epig.set_index('Unnamed: 0')\n",
    "    \n",
    "    # Metadata\n",
    "    meta = pd.read_csv('/nfs/answer/fraenkel_internal/current_omics/proteomics/full_prot_metadata203_03082023.csv',\n",
    "                        error_bad_lines=False)\n",
    "    meta = meta.set_index('Unnamed: 0')\n",
    "    return [prot, tran, epig, meta]\n",
    "    #return [prot_raw, prot, tran_raw, tran, epig_raw, epig, meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch rows and columns to match snf format\n",
    "def transpose(data):\n",
    "    data_return = []\n",
    "    for d in data[:-1]:\n",
    "        data_return.append(d.T)\n",
    "    data_return.append(data[-1])\n",
    "    \n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only samples present in all datasets\n",
    "def filter_and_sort(data):\n",
    "    \n",
    "    meta = data[-1]\n",
    "    epig = data[-2]\n",
    "    \n",
    "    meta = meta[meta.index.isin(epig.index)]\n",
    "\n",
    "    data_return = []\n",
    "    \n",
    "    for d in data:\n",
    "        d = d[d.index.isin(meta.index)]\n",
    "        data_return.append(d.sort_index())\n",
    "    \n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "data = transpose(data)\n",
    "prot, tran, epig, meta = filter_and_sort(data)\n",
    "#prot_raw, prot, tran_raw, tran, epig_raw, epig, meta = filter_and_sort(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with all 0s\n",
    "def normalize(prot_raw, tran_raw, epig_raw):\n",
    "    dfs = [prot_raw, tran_raw, epig_raw]\n",
    "    \n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].loc[:, (dfs[i] != 0).any(axis=0)]\n",
    "    \n",
    "    # Z-score all columns of DFs\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].astype(float)\n",
    "        for col, colData in dfs[i].iteritems():\n",
    "            dfs[i][col] = stats.zscore(dfs[i][col])\n",
    "    \n",
    "    prot_z = dfs[0]\n",
    "    tran_z = dfs[1]\n",
    "    epig_z = dfs[2]\n",
    "    \n",
    "    return dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "#prot_z, tran_z, epig_z = normalize(prot_raw, tran_raw, epig_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define labels to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GUID_orig', 'GUID_vial', 'GUID', 'attribute_ExperimentalGroup',\n",
       "       'attribute_SampleType', 'attribute_TechnicalGroup', 'attribute_Species',\n",
       "       'attribute_DataType', 'attribute_BiologicalGroup', 'Level2', 'Level3',\n",
       "       'order', 'MS_batch', 'Digestion_batch', 'Differentiation_batch', 'Case',\n",
       "       'Sex.x', 'Race', 'Site.of.Onset', 'ALSFRS.R.Baseline', 'nefh', 'isl1',\n",
       "       'nkx6', 'tuj1', 's100b', 'nestin', 'Primary.Tissue', 'SOD1', 'C9',\n",
       "       'PBMC', 'CHMP7', 'Group', 'Cell.Line', 'Site', 'shipment', 'Batch #',\n",
       "       'Sex.y', 'Mean DAPI', '%SMI32', '%ISL1', '%NKX6.1', '%TUJ1', '%S100b',\n",
       "       '% Nestin', 'Number of Visits', 'Subject Group', 'Age At Symptom Onset',\n",
       "       'Age At Death', 'ALSFRS-R Baseline', 'ALSFRS-R Latest',\n",
       "       'ALSFRS-R Progression Slope', 'Sex', 'Primary Tissue', 'progressor',\n",
       "       'estimated_slope_alsfrsr', 'SOD1_gen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CASE', 'CTRL'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See unique values in column\n",
    "meta['Case'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progressor\n",
    "actual_labels = meta['progressor'].map({'AMBIGUOUS': 0, 'fast': 1, 'slow':2, np.nan:3}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site.of.Onset\n",
    "actual_labels = meta['Site.of.Onset'].map({'Limb': 0, 'Bulbar': 1, 'Axial':2, 'Multiple': 3, 'Other': 4, np.nan:5}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case\n",
    "actual_labels = meta['Case'].map({'CASE': 1, 'CTRL': 0}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex.x\n",
    "actual_labels = meta['Sex.x'].map({'Male': 1, 'Female': 0}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bridgetl/.conda/envs/fresh-env/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# ALSFRS-R Progression Slope\n",
    "actual_labels = meta['ALSFRS-R Progression Slope']\n",
    "s=np.isnan(actual_labels)\n",
    "actual_labels[s] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C9\n",
    "actual_labels = meta['C9'].map({'POS': 0, 'NEG': 1, 'CTRL': 2, 'UNK':3}).array\n",
    "#meta_f = meta_f[meta_f.C9 != 'UNK']\n",
    "#actual_labels = meta_f['C9'].map({'POS': 0, 'NEG': 1, 'CTRL': 2}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOD1\n",
    "actual_labels = meta['SOD1'].map({'POS': 0, 'NEG': 1, 'CTRL': 2, 'UNK':3}).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBMC\n",
    "actual_labels = meta['PBMC'].map({'PBMC/T-Cell': 0, 'PBMC/NT-Cell': 1, np.nan:2}).array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_snf(prot, tran, epig):\n",
    "    '''\n",
    "    Apply SNF to data.\n",
    "    Args:\n",
    "        prot: DataFrame of normalized proteomics data\n",
    "        tran: DataFrame of normalized transcriptomics data\n",
    "        epig: DataFrame of normalized epigenomics data\n",
    "    Returns:\n",
    "        best: best number of clusters by spectral clustering\n",
    "        affinity_networks: array with coefficients of similarity\n",
    "            between each pair of patients for a single modality\n",
    "        fused_network: array with coefficients of fused similarity\n",
    "            between each pair of patients\n",
    "        fused_labels: array of label of 0/1 for each patient,\n",
    "            determined by SNF and spectral clustering\n",
    "    '''\n",
    "    data = [prot, tran, epig]\n",
    "    \n",
    "    # K: num of nearest neighbors to consider when constructing affinity matrix\n",
    "        # good value for K is sqrt(N)\n",
    "    # mu: scaling factor that weights affinity matrix\n",
    "    affinity_networks = snf.make_affinity(data, metric='euclidean', K=14, mu=0.5)\n",
    "    \n",
    "    # Run SNF algorithm\n",
    "    fused_network = snf.snf(affinity_networks, K=14)\n",
    "    \n",
    "    # Estimate the number of clusters in the data via the “eigengap” method\n",
    "    best, second = snf.get_n_clusters(fused_network)\n",
    "    \n",
    "    # Get labels from clusters\n",
    "    fused_labels = spectral_clustering(fused_network, n_clusters=best)\n",
    "    \n",
    "    return best, affinity_networks, fused_network, fused_labels\n",
    "\n",
    "# With proteomics data normalized by code\n",
    "#best, fused_network, fused_labels = apply_snf(prot_z, tran_z, epig_z)\n",
    "# With already normalized proteomics data\n",
    "best, affinity_networks, fused_network, fused_labels = apply_snf(prot, tran, epig)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_measure_score': 0.007730743558228625,\n",
       " 'nmi': 0.007730743558228624,\n",
       " 'silhouette score': 0.23434490987229858}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(best, affinity_networks, fused_network, fused_labels, actual_labels):\n",
    "    '''\n",
    "    Scores to evaluate performance of SNF\n",
    "    Returns:\n",
    "        scores_dict: dictionary of key=score name, value=score value\n",
    "            for v_measure_score, nmi, and silhouette score\n",
    "    '''\n",
    "    # v_measure_score ranges from 0 to 1, where 1 indicates perfect overlap between the derived and true labels and 0 indicates no overlap\n",
    "    v_measure = v_measure_score(fused_labels, actual_labels)\n",
    "    \n",
    "    # Generate cluster labels from the individual affinity matrices\n",
    "    labels = [actual_labels, fused_labels]\n",
    "    for arr in affinity_networks:\n",
    "        labels += [spectral_clustering(arr, n_clusters=best)]\n",
    "        \n",
    "    '''\n",
    "    Normalized mutual information score (NMI) between the labels\n",
    "    generated by SNF and the ones we just obtained.\n",
    "    0 indicates no overlap and 1 indicates a perfect correspondence\n",
    "    between the two sets of labels.\n",
    "    '''\n",
    "    nmi = normalized_mutual_info_score(actual_labels, fused_labels)\n",
    "    '''\n",
    "    Silhouette score\n",
    "    Range from -1 to 1, where -1 indicates a poor clustering solution\n",
    "    and 1 indicates a fantastic solution.\n",
    "    '''\n",
    "    np.fill_diagonal(fused_network, 0)\n",
    "    sil = metrics.silhouette_score(fused_network, fused_labels)\n",
    "    \n",
    "    return v_measure, nmi, sil\n",
    "\n",
    "scores = score(best, affinity_networks, fused_network, fused_labels, actual_labels)\n",
    "scores_dict = {'v_measure_score': scores[0], 'nmi': scores[1], 'silhouette score': scores[2]}\n",
    "scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "from pyvis import network as net\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_colors(network, col_attribute, cmap_name=\"Accent\"):\n",
    "    \"\"\"\n",
    "    Function to add node colors based on existing node attribute.\n",
    "    \n",
    "    network: networkx object\n",
    "    col_attribute: Name of attribute to use for determining node colors\n",
    "    cmap_name: Name of matplotlib colormap to use (default: 'Accent')\n",
    "    \"\"\"\n",
    "    source_att = nx.get_node_attributes(network, col_attribute)\n",
    "    \n",
    "    # Get colors\n",
    "    cmap = cm.get_cmap(cmap_name, len(set(source_att.values())))    \n",
    "    source_dict = dict(zip(list(set(source_att.values())),\n",
    "                           np.arange(len(set(source_att.values())))))\n",
    "    node_colors = {n:mpl.colors.rgb2hex(cmap(source_dict[v]), keep_alpha=True) for (n, v) in source_att.items()}\n",
    "    # Set colors\n",
    "    nx.set_node_attributes(network, node_colors, 'color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00543871, 0.        , ..., 0.00657465, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00543871, 0.        , 0.        , ..., 0.00545585, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00647958,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00657465, 0.00545585, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00647958, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(fused_network)\n",
    "fused_network_vis = fused_network.copy()\n",
    "\n",
    "# Set all entries below 75% quartile to 0 to avoid too many network connections\n",
    "cutoff = np.percentile(fused_network_vis, 75)\n",
    "for row in fused_network_vis:\n",
    "    row[row < cutoff] = 0\n",
    "fused_network_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networkx object\n",
    "nt = nx.from_numpy_matrix(fused_network_vis)\n",
    "nt = nx.relabel_nodes(nt, dict(zip(np.arange(n), prot.index.values)))\n",
    "\n",
    "# Set some attributes from metadata\n",
    "meta_net = meta.copy()\n",
    "meta_net['fused_labels'] = fused_labels\n",
    "nx.set_node_attributes(nt, meta_net.loc[:, ['Case', 'Sex.x', 'fused_labels', ]].to_dict('index'))\n",
    "\n",
    "# Set node colors \n",
    "add_node_colors(nt, col_attribute='fused_labels')\n",
    "#nt.nodes['NEUAB000NKC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "nx.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"750px\"\n",
       "            height=\"750px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fecb3b98048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subgraph for ease of visualization\n",
    "sub_nt = nt.subgraph(list(nt.nodes)[:100])\n",
    "\n",
    "ntw = net.Network('750px', '750px', notebook=True)\n",
    "ntw.toggle_physics(False)\n",
    "ntw.from_nx(sub_nt)\n",
    "\n",
    "ntw.show('nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fresh-env)",
   "language": "python",
   "name": "fresh-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
